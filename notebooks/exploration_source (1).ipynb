{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration de la base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!conda install pandas #dans la console\n",
    "from datetime import date, timedelta\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Racine des fichiers quotidiens\n",
    "BASE_URL = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/{}.csv'\n",
    "\n",
    "# Dates de diponibilité des fichiers\n",
    "START_DATE = date(2020, 1, 22)\n",
    "END_DATE = date(2020, 3, 15)\n",
    "\n",
    "#Répertoire de sauvegarde des fichiers bruts\n",
    "RAWFILES_DIR =' data/raw/'\n",
    "PROCESSED_DIR = 'data/processed/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Racine des fichiers quotidiens\n",
    "BASE_URL = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/{}.csv'\n",
    "\n",
    "# Dates de disponibilité des fichiers\n",
    "START_DATE = date(2020, 1, 22)\n",
    "END_DATE = date(2020, 3, 15)\n",
    "\n",
    "# Répertoire de sauvegarde des fichiers bruts\n",
    "RAWFILES_DIR = '../data/raw/'\n",
    "PROCESSED_DIR = '../data/processed/'\n",
    "\n",
    "# Fichier principal\n",
    "ALL_DATA_FILE = 'all_data.csv'\n",
    "\n",
    "#TODO: A remplacer par la lecture du fichier env.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boucle de récupération des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = END_DATE - START_DATE       # as timedelta\n",
    "\n",
    "for i in range(delta.days + 1):\n",
    "    day = START_DATE + timedelta(days=i)\n",
    "    day_label = day.strftime(\"%m-%d-%Y\")\n",
    "    #print(day_label)\n",
    "    virus_df = pd.read_csv(BASE_URL.format(day_label), sep=',', parse_dates=['Last Update'])\n",
    "    virus_df.to_csv(os.path.join(RAWFILES_DIR, day_label + '.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = END_DATE - START_DATE       # as timedelta\n",
    "\n",
    "for i in range(delta.days + 1):\n",
    "    day = START_DATE + timedelta(days=i)\n",
    "    day_label = day.strftime(\"%m-%d-%Y\")\n",
    "    \n",
    "    virus_df = pd.read_csv(BASE_URL.format(day_label), sep=\",\", parse_dates=[\"Last Update\"])\n",
    "    virus_df.to_csv(os.path.join(RAWFILES_DIR, day_label + '.csv'), index=False)\n",
    "    \n",
    "    #print(day_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Province/State            object\n",
       "Country/Region            object\n",
       "Last Update       datetime64[ns]\n",
       "Confirmed                  int64\n",
       "Deaths                     int64\n",
       "Recovered                  int64\n",
       "Latitude                 float64\n",
       "Longitude                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "virus_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constitution de la table de référence lat/long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "df_list = []\n",
    "\n",
    "# Lecture des fichiers récupérés et sélection de ceux qui ont une lat / long\n",
    "for file in glob.glob(os.path.join(RAWFILES_DIR, '*.csv')):\n",
    "    virus_df = pd.read_csv(file, sep=',')\n",
    "    if 'Latitude' in virus_df.columns and 'Longitude' in virus_df.columns:\n",
    "        df_list.append(virus_df)\n",
    "\n",
    "all_df = pd.concat(df_list)\n",
    "\n",
    "# Table de référence pour les lat / long\n",
    "(all_df[[\"Province/State\", \"Country/Region\", \"Latitude\", \"Longitude\"]]\n",
    " .drop_duplicates(subset=[\"Province/State\", \"Country/Region\"])\n",
    " .sort_values(by=[\"Country/Region\", \"Province/State\"])\n",
    " .to_csv(os.path.join(PROCESSED_DIR, \"lat_long_table.csv\"), index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(621, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(all_df[[\"Province/State\", \"Country/Region\", \"Latitude\", \"Longitude\"]]\n",
    " .drop_duplicates()\n",
    " .shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(502, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(all_df[[\"Province/State\", \"Country/Region\", \"Latitude\", \"Longitude\"]]\n",
    " .drop_duplicates()\n",
    " .drop_duplicates(subset=[\"Province/State\", \"Country/Region\"])\n",
    " .shape\n",
    ")\n",
    "# 3 villes qui ont des latitudes-longitudes différentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Italy</td>\n",
       "      <td>43.0000</td>\n",
       "      <td>12.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Spain</td>\n",
       "      <td>40.0000</td>\n",
       "      <td>-4.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Germany</td>\n",
       "      <td>51.0000</td>\n",
       "      <td>9.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Japan</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>138.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>63.0000</td>\n",
       "      <td>16.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Mayotte</td>\n",
       "      <td>France</td>\n",
       "      <td>-12.8275</td>\n",
       "      <td>45.1662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>North Dakota</td>\n",
       "      <td>US</td>\n",
       "      <td>47.5289</td>\n",
       "      <td>-99.7840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>12.5211</td>\n",
       "      <td>-69.9683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>United States Virgin Islands</td>\n",
       "      <td>US</td>\n",
       "      <td>18.3358</td>\n",
       "      <td>-64.8963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>53.4167</td>\n",
       "      <td>-8.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Province/State Country/Region  Latitude  Longitude\n",
       "1                             NaN          Italy   43.0000    12.0000\n",
       "5                             NaN          Spain   40.0000    -4.0000\n",
       "6                             NaN        Germany   51.0000     9.0000\n",
       "16                            NaN          Japan   36.0000   138.0000\n",
       "25                            NaN         Sweden   63.0000    16.0000\n",
       "..                            ...            ...       ...        ...\n",
       "232                       Mayotte         France  -12.8275    45.1662\n",
       "251                  North Dakota             US   47.5289   -99.7840\n",
       "235                         Aruba    Netherlands   12.5211   -69.9683\n",
       "248  United States Virgin Islands             US   18.3358   -64.8963\n",
       "78                            NaN        Ireland   53.4167    -8.0000\n",
       "\n",
       "[234 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(all_df[[\"Province/State\", \"Country/Region\", \"Latitude\", \"Longitude\"]]\n",
    " .drop_duplicates()\n",
    " [(all_df[[\"Province/State\", \"Country/Region\", \"Latitude\", \"Longitude\"]]\n",
    "   .drop_duplicates()\n",
    "   .duplicated(subset=[\"Province/State\", \"Country/Region\"], keep=False))]\n",
    ")\n",
    "# Les 3 pays qui ont \"bougé\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction d'une table unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_catalog = {\n",
    "    'Last Update':[\"<M8[ns]\"],\n",
    "    \"Confirmed\":[\"float64\", \"int64\"],\n",
    "    \"Deaths\":[\"float64\", \"int64\"],\n",
    "    \"Recovered\":[\"float64\", \"int64\"],\n",
    "    \"Latitude\":[\"float64\"],\n",
    "    \"Longitude\":[\"float64\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "latlong_df = pd.read_csv(os.path.join(PROCESSED_DIR, \"lat_long_table.csv\"))\n",
    "\n",
    "# Lecture des fichiers récupérés et sélection de ceux qui ont une lat / long\n",
    "for file in glob.glob(os.path.join(RAWFILES_DIR, '*.csv')):\n",
    "    virus_df = pd.read_csv(file, sep=',', parse_dates=[\"Last Update\"])\n",
    "    if not('Latitude' in virus_df.columns and 'Longitude' in virus_df.columns):\n",
    "        virus_df = virus_df.merge(latlong_df, on=[\"Province/State\", \"Country/Region\"], how='left')\n",
    "    \n",
    "    # Checker le type des variables dans l'importation de chaque fichier.\n",
    "    for field, types in data_catalog.items():\n",
    "        assert virus_df[field].dtypes in types, f\"bad type for {field} in {file}\"\n",
    "\n",
    "    df_list.append(virus_df.assign(source=os.path.basename(file)))\n",
    "    \n",
    "all_df = pd.concat(df_list)\n",
    "\n",
    "# Sauvegarde de la table totale\n",
    "all_df.to_csv(os.path.join(PROCESSED_DIR, 'all_data.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "latlong_df = pd.read_csv(os.path.join(PROCESSED_DIR, 'lat_long_table.csv'))\n",
    "\n",
    "# Lecture des fichiers récupérés et sélection de ceux qui ont une lat / long\n",
    "for file in glob.glob(os.path.join(RAWFILES_DIR, '*.csv')):\n",
    "    virus_df = pd.read_csv(file, sep=',', parse_dates=['Last Update'])\n",
    "    if not('Latitude' in virus_df.columns and 'Longitude' in virus_df.columns):\n",
    "        virus_df = virus_df.merge(latlong_df, on=['Province/State', 'Country/Region'], how='left')\n",
    "        \n",
    "    for field, types in data_catalog.items():\n",
    "        assert virus_df[field].dtypes in types, f\"Bad type for {field} in {file}\"\n",
    "        \n",
    "    df_list.append(virus_df.assign(source=os.path.basename(file)))\n",
    "\n",
    "all_df = pd.concat(df_list)\n",
    "\n",
    "# Sauvegarde de la table totale\n",
    "all_df.to_csv(os.path.join(PROCESSED_DIR, 'all_data.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Projet Corona (Python)",
   "language": "python",
   "name": "corona"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
